{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "\n",
    "A multinational corporation with nine distinct areas of operation faces a challenge in selecting suitable candidates for managerial (and below positions) promotions and providing them with timely training. The announcement of final promotions occurs only after evaluations, resulting in delays in transitioning to new roles. Therefore, the company seeks assistance in identifying qualified candidates at specific checkpoints to accelerate the promotion process as a whole.\n",
    "\n",
    "The company has historical data comprising of demographic, educational, work experience and skill details, along with the promotion details.\n",
    "\n",
    "\n",
    "## Solution:\n",
    "\n",
    "As the company has access to historical data, it makes sense to build a machine learning model that can find the traits of employees fit for promotion. As the goal is find the list of employees who can be promoted, it will come under supervised classification category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing the libraries and reading the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install scikit-learn\n",
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler \n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import * \n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('hr_train.csv')\n",
    "test_data = pd.read_csv('hr_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the employee_id column is an ID column, it serves no purpose in the modeling process. So, we will delete the employee_id column from the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del training_data['employee_id']\n",
    "del test_data['employee_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [c for c in training_data.columns if training_data[c].dtypes=='object']\n",
    "numeric_columns = [n for n in training_data.columns if n not in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_categorical_columns = ['department', 'region', 'education', 'gender', 'recruitment_channel','awards_won?', \n",
    "             'previous_year_rating','length_of_service', 'no_of_trainings']\n",
    "true_numeric_columns = [c for c in training_data.columns if c not in true_categorical_columns]\n",
    "true_numeric_columns.remove('is_promoted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very few employees whose work experience is 30 years or more (0.1%). These can be considered as outliers and it is a best practice to remove them before we feed data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data[training_data.length_of_service<30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would be applying imputation strategy for the education and previous_year_rating columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "department              0\n",
       "region                  0\n",
       "education               0\n",
       "gender                  0\n",
       "recruitment_channel     0\n",
       "no_of_trainings         0\n",
       "age                     0\n",
       "previous_year_rating    0\n",
       "length_of_service       0\n",
       "awards_won?             0\n",
       "avg_training_score      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = training_data.pop('is_promoted')\n",
    "all_data = pd.concat([training_data, test_data], axis=0)\n",
    "si_most_frequent = SimpleImputer(strategy= 'most_frequent')\n",
    "all_data['education'] = si_most_frequent.fit_transform(all_data.education.values.reshape(-1, 1))\n",
    "si_mean = SimpleImputer(strategy='mean')\n",
    "all_data['previous_year_rating'] = si_mean.fit_transform(all_data.previous_year_rating.values.reshape(-1, 1))\n",
    "all_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Categorical features into dummy ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54752, 57), (23490, 57))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_dummy = pd.get_dummies(all_data)\n",
    "new_training_data = all_data_dummy.iloc[:len(training_data)]\n",
    "new_test_data = all_data_dummy.iloc[len(training_data):]\n",
    "new_training_data.shape, new_test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying StandardScaler for standardizing the features in training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "new_training_data = ss.fit_transform(new_training_data)\n",
    "new_test_data = ss.transform(new_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Training (Logistic Regression) and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Stratified K fold cross validation on the data, training model and evaluating the performance. As the purpose of this activity is to show how AI/ML model outputs can be used for Decision Intelligence, we would keep the modeling process preety simple and would not train multiple algorithms to see which ones perform the best. Instead, we will train a Logistic Regression model with default/minimal changes to the parameters and will see how the results can be interpreted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "train: 0.7931202718718571 val : 0.7819824102253672\n",
      "--------------------\n",
      "fold: 1\n",
      "train: 0.7897501709069539 val : 0.79278434937156\n",
      "--------------------\n",
      "fold: 2\n",
      "train: 0.7868061847019592 val : 0.804318671120831\n",
      "--------------------\n",
      "fold: 3\n",
      "train: 0.7930340720726938 val : 0.7815370354855481\n",
      "--------------------\n",
      "fold: 4\n",
      "train: 0.7943494182608088 val : 0.7806564317616108\n",
      "--------------------\n",
      "log reg  roc_auc=   78.83\n",
      "F1 Score=  44.66\n",
      "Recall Score=  29.24\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "probs = np.zeros(len(new_training_data))\n",
    "y_le = target.values\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_, (train_ind, val_ind) in enumerate(folds.split(new_training_data, y_le)):\n",
    "    print('fold:', fold_)\n",
    "    X_tr, X_test = new_training_data[train_ind], new_training_data[val_ind]\n",
    "    y_tr, y_test = y_le[train_ind], y_le[val_ind]\n",
    "    clf = LogisticRegression(max_iter=200, random_state=2020)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    probs[val_ind]= clf.predict_proba(X_test)[:, 1]\n",
    "    y = clf.predict_proba(X_tr)[:,1] \n",
    "    print('train:',roc_auc_score(y_tr, y),'val :' , roc_auc_score(y_test, (probs[val_ind])))\n",
    "    print(20 * '-')\n",
    "    \n",
    "    scores.append(roc_auc_score(y_test, probs[val_ind]))\n",
    "    \n",
    "print('log reg  roc_auc=  ', round(np.mean(scores)*100,2))\n",
    "probs_rnd = np.where(probs > 0.5, 1, 0)\n",
    "print('F1 Score= ', round(f1_score(target, probs_rnd)*100,2))\n",
    "print('Recall Score= ', round(recall_score(target, probs_rnd)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, the model performance is satisfactory and with additional techniques, it can be improved. Now, the HR team can leverage the predictions made on the employees through the ML model, and create a list of potential promotion candidates based on their probability scores.** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
